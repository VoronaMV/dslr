{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset_train.csv', index_col='Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transoform birthdate and add column year (year of study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hogwarts House</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Best Hand</th>\n",
       "      <th>Arithmancy</th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Herbology</th>\n",
       "      <th>Defense Against the Dark Arts</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Muggle Studies</th>\n",
       "      <th>Ancient Runes</th>\n",
       "      <th>History of Magic</th>\n",
       "      <th>Transfiguration</th>\n",
       "      <th>Potions</th>\n",
       "      <th>Care of Magical Creatures</th>\n",
       "      <th>Charms</th>\n",
       "      <th>Flying</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>Tamara</td>\n",
       "      <td>Hsu</td>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>Left</td>\n",
       "      <td>58384.0</td>\n",
       "      <td>-487.886086</td>\n",
       "      <td>5.727180</td>\n",
       "      <td>4.878861</td>\n",
       "      <td>4.722</td>\n",
       "      <td>272.035831</td>\n",
       "      <td>532.484226</td>\n",
       "      <td>5.231058</td>\n",
       "      <td>1039.788281</td>\n",
       "      <td>3.790369</td>\n",
       "      <td>0.715939</td>\n",
       "      <td>-232.79405</td>\n",
       "      <td>-26.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slytherin</td>\n",
       "      <td>Erich</td>\n",
       "      <td>Paredes</td>\n",
       "      <td>1999-10-14</td>\n",
       "      <td>Right</td>\n",
       "      <td>67239.0</td>\n",
       "      <td>-552.060507</td>\n",
       "      <td>-5.987446</td>\n",
       "      <td>5.520605</td>\n",
       "      <td>-5.612</td>\n",
       "      <td>-487.340557</td>\n",
       "      <td>367.760303</td>\n",
       "      <td>4.107170</td>\n",
       "      <td>1058.944592</td>\n",
       "      <td>7.248742</td>\n",
       "      <td>0.091674</td>\n",
       "      <td>-252.18425</td>\n",
       "      <td>-113.45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>Stephany</td>\n",
       "      <td>Braun</td>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>Left</td>\n",
       "      <td>23702.0</td>\n",
       "      <td>-366.076117</td>\n",
       "      <td>7.725017</td>\n",
       "      <td>3.660761</td>\n",
       "      <td>6.140</td>\n",
       "      <td>664.893521</td>\n",
       "      <td>602.585284</td>\n",
       "      <td>3.555579</td>\n",
       "      <td>1088.088348</td>\n",
       "      <td>8.728531</td>\n",
       "      <td>-0.515327</td>\n",
       "      <td>-227.34265</td>\n",
       "      <td>30.42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Vesta</td>\n",
       "      <td>Mcmichael</td>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Left</td>\n",
       "      <td>32667.0</td>\n",
       "      <td>697.742809</td>\n",
       "      <td>-6.497214</td>\n",
       "      <td>-6.977428</td>\n",
       "      <td>4.026</td>\n",
       "      <td>-537.001128</td>\n",
       "      <td>523.982133</td>\n",
       "      <td>-4.809637</td>\n",
       "      <td>920.391449</td>\n",
       "      <td>0.821911</td>\n",
       "      <td>-0.014040</td>\n",
       "      <td>-256.84675</td>\n",
       "      <td>200.64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>Gaston</td>\n",
       "      <td>Gibbs</td>\n",
       "      <td>1998-09-27</td>\n",
       "      <td>Left</td>\n",
       "      <td>60158.0</td>\n",
       "      <td>436.775204</td>\n",
       "      <td>-7.820623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.236</td>\n",
       "      <td>-444.262537</td>\n",
       "      <td>599.324514</td>\n",
       "      <td>-3.444377</td>\n",
       "      <td>937.434724</td>\n",
       "      <td>4.311066</td>\n",
       "      <td>-0.264070</td>\n",
       "      <td>-256.38730</td>\n",
       "      <td>157.98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hogwarts House First Name  Last Name    Birthday Best Hand  Arithmancy  \\\n",
       "Index                                                                          \n",
       "0          Ravenclaw     Tamara        Hsu  2000-03-30      Left     58384.0   \n",
       "1          Slytherin      Erich    Paredes  1999-10-14     Right     67239.0   \n",
       "2          Ravenclaw   Stephany      Braun  1999-11-03      Left     23702.0   \n",
       "3         Gryffindor      Vesta  Mcmichael  2000-08-19      Left     32667.0   \n",
       "4         Gryffindor     Gaston      Gibbs  1998-09-27      Left     60158.0   \n",
       "\n",
       "        Astronomy  Herbology  Defense Against the Dark Arts  Divination  \\\n",
       "Index                                                                     \n",
       "0     -487.886086   5.727180                       4.878861       4.722   \n",
       "1     -552.060507  -5.987446                       5.520605      -5.612   \n",
       "2     -366.076117   7.725017                       3.660761       6.140   \n",
       "3      697.742809  -6.497214                      -6.977428       4.026   \n",
       "4      436.775204  -7.820623                            NaN       2.236   \n",
       "\n",
       "       Muggle Studies  Ancient Runes  History of Magic  Transfiguration  \\\n",
       "Index                                                                     \n",
       "0          272.035831     532.484226          5.231058      1039.788281   \n",
       "1         -487.340557     367.760303          4.107170      1058.944592   \n",
       "2          664.893521     602.585284          3.555579      1088.088348   \n",
       "3         -537.001128     523.982133         -4.809637       920.391449   \n",
       "4         -444.262537     599.324514         -3.444377       937.434724   \n",
       "\n",
       "        Potions  Care of Magical Creatures     Charms  Flying  year  \n",
       "Index                                                                \n",
       "0      3.790369                   0.715939 -232.79405  -26.89     4  \n",
       "1      7.248742                   0.091674 -252.18425 -113.45     3  \n",
       "2      8.728531                  -0.515327 -227.34265   30.42     3  \n",
       "3      0.821911                  -0.014040 -256.84675  200.64     4  \n",
       "4      4.311066                  -0.264070 -256.38730  157.98     2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['year'] = df_train['Birthday'].apply(lambda x: int(x.split('-')[0]))\n",
    "df_train['year'] = df_train['year'] - df_train['year'].min()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### FrameHandler class has functionality of dataframe data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameHandler:\n",
    "    \n",
    "    @classmethod\n",
    "    def cut_features(cls, df: pd.DataFrame, features=[]) -> pd.DataFrame:\n",
    "        return df.drop(columns=features, inplace=False)\n",
    "    \n",
    "    @classmethod\n",
    "    def normalize_data(cls, df: pd.DataFrame, columns=[]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Normalize all columns data if colums argument doesn't set.\n",
    "        Otherwice - normizes only defined columns.\n",
    "        \"\"\"\n",
    "        normalized_df = df.copy()    \n",
    "        if columns:\n",
    "            normalized_df[columns] = cls.__normalize(normalized_df[columns])\n",
    "        else:\n",
    "            normalized_df = cls.__normalize(normalized_df)\n",
    "        return normalized_df\n",
    "    \n",
    "    @classmethod\n",
    "    def __normalize(cls, df):\n",
    "        return (df - df.min()) / (df.max() - df.min())\n",
    "    \n",
    "    @classmethod\n",
    "    def filter_numeric(cls, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df._get_numeric_data()\n",
    "    \n",
    "    @classmethod\n",
    "    def prepend_ones(cls, df: pd.DataFrame, column_name: str='bias') -> pd.DataFrame:\n",
    "        rows, _ = df.shape\n",
    "        ones = np.ones(rows)\n",
    "        bias_df = pd.DataFrame({column_name: ones}, index=df.index)\n",
    "        concatenated_df = pd.concat([bias_df, df], axis=1)\n",
    "        return concatenated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(df: pd.DataFrame, drop_features=[], normalize=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare dataframe for model:\n",
    "        - drop features were received\n",
    "        - create dummies\n",
    "        - filter only numeric values\n",
    "        - clean datafrate from NaN values\n",
    "        - normalize data if \"normalize\" is True\n",
    "    \"\"\"\n",
    "    prepared_df = FrameHandler.cut_features(df_train, drop_features)\n",
    "    \n",
    "    # create dummie variables for hands and houses\n",
    "    hand_dummies_df = pd.get_dummies(prepared_df['Best Hand'])\n",
    "    house_dummies_df = pd.get_dummies(prepared_df['Hogwarts House'])\n",
    "    prepared_df = pd.concat([prepared_df, hand_dummies_df, house_dummies_df], axis=1)\n",
    "    \n",
    "    # filter only numeric columns and drop NaN\n",
    "    prepared_df = FrameHandler.filter_numeric(prepared_df)\n",
    "    prepared_df.dropna(how='any', inplace=True)\n",
    "\n",
    "    # normalize data\n",
    "    if normalize:\n",
    "        prepared_df = FrameHandler.normalize_data(prepared_df)\n",
    "    \n",
    "    prepared_df = FrameHandler.prepend_ones(prepared_df)\n",
    "    return prepared_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>Herbology</th>\n",
       "      <th>Divination</th>\n",
       "      <th>Muggle Studies</th>\n",
       "      <th>Ancient Runes</th>\n",
       "      <th>History of Magic</th>\n",
       "      <th>Transfiguration</th>\n",
       "      <th>Potions</th>\n",
       "      <th>Charms</th>\n",
       "      <th>Flying</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Gryffindor</th>\n",
       "      <th>Hufflepuff</th>\n",
       "      <th>Ravenclaw</th>\n",
       "      <th>Slytherin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.241486</td>\n",
       "      <td>0.778094</td>\n",
       "      <td>0.716936</td>\n",
       "      <td>0.616003</td>\n",
       "      <td>0.538679</td>\n",
       "      <td>0.672324</td>\n",
       "      <td>0.708932</td>\n",
       "      <td>0.431946</td>\n",
       "      <td>0.793213</td>\n",
       "      <td>0.335649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>0.209214</td>\n",
       "      <td>0.166054</td>\n",
       "      <td>0.260548</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.617016</td>\n",
       "      <td>0.810917</td>\n",
       "      <td>0.633512</td>\n",
       "      <td>0.248862</td>\n",
       "      <td>0.147696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.302914</td>\n",
       "      <td>0.875112</td>\n",
       "      <td>0.792526</td>\n",
       "      <td>0.799895</td>\n",
       "      <td>0.690568</td>\n",
       "      <td>0.589872</td>\n",
       "      <td>0.966075</td>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.946253</td>\n",
       "      <td>0.460090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.839396</td>\n",
       "      <td>0.184459</td>\n",
       "      <td>0.679834</td>\n",
       "      <td>0.237302</td>\n",
       "      <td>0.520257</td>\n",
       "      <td>0.178215</td>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.258934</td>\n",
       "      <td>0.117970</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707791</td>\n",
       "      <td>0.120192</td>\n",
       "      <td>0.584413</td>\n",
       "      <td>0.280712</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.164015</td>\n",
       "      <td>0.462294</td>\n",
       "      <td>0.130868</td>\n",
       "      <td>0.737070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.178044</td>\n",
       "      <td>0.291683</td>\n",
       "      <td>0.113812</td>\n",
       "      <td>0.282240</td>\n",
       "      <td>0.243393</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.895932</td>\n",
       "      <td>0.367859</td>\n",
       "      <td>0.318713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737857</td>\n",
       "      <td>0.246682</td>\n",
       "      <td>0.777334</td>\n",
       "      <td>0.195384</td>\n",
       "      <td>0.615290</td>\n",
       "      <td>0.109860</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.274357</td>\n",
       "      <td>0.246298</td>\n",
       "      <td>0.924089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.753389</td>\n",
       "      <td>0.884688</td>\n",
       "      <td>0.644117</td>\n",
       "      <td>0.302319</td>\n",
       "      <td>0.124816</td>\n",
       "      <td>0.659901</td>\n",
       "      <td>0.717590</td>\n",
       "      <td>0.331609</td>\n",
       "      <td>0.462473</td>\n",
       "      <td>0.393842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.766294</td>\n",
       "      <td>0.750840</td>\n",
       "      <td>0.240207</td>\n",
       "      <td>0.435518</td>\n",
       "      <td>0.695384</td>\n",
       "      <td>0.690283</td>\n",
       "      <td>0.752667</td>\n",
       "      <td>0.515352</td>\n",
       "      <td>0.534329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708689</td>\n",
       "      <td>0.758346</td>\n",
       "      <td>0.625886</td>\n",
       "      <td>0.245934</td>\n",
       "      <td>0.288595</td>\n",
       "      <td>0.651182</td>\n",
       "      <td>0.746059</td>\n",
       "      <td>0.582702</td>\n",
       "      <td>0.452979</td>\n",
       "      <td>0.438898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845121</td>\n",
       "      <td>0.582790</td>\n",
       "      <td>0.843222</td>\n",
       "      <td>0.334799</td>\n",
       "      <td>0.328546</td>\n",
       "      <td>0.724959</td>\n",
       "      <td>0.694238</td>\n",
       "      <td>0.683725</td>\n",
       "      <td>0.478521</td>\n",
       "      <td>0.410453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213091</td>\n",
       "      <td>0.145044</td>\n",
       "      <td>0.135775</td>\n",
       "      <td>0.338903</td>\n",
       "      <td>0.233536</td>\n",
       "      <td>0.558336</td>\n",
       "      <td>0.936757</td>\n",
       "      <td>0.849164</td>\n",
       "      <td>0.278595</td>\n",
       "      <td>0.219416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  Astronomy  Herbology  Divination  Muggle Studies  Ancient Runes  \\\n",
       "Index                                                                          \n",
       "0       1.0   0.241486   0.778094    0.716936        0.616003       0.538679   \n",
       "1       1.0   0.209123   0.209214    0.166054        0.260548       0.181768   \n",
       "2       1.0   0.302914   0.875112    0.792526        0.799895       0.690568   \n",
       "3       1.0   0.839396   0.184459    0.679834        0.237302       0.520257   \n",
       "4       1.0   0.707791   0.120192    0.584413        0.280712       0.683503   \n",
       "5       1.0   0.178044   0.291683    0.113812        0.282240       0.243393   \n",
       "8       1.0   0.737857   0.246682    0.777334        0.195384       0.615290   \n",
       "9       1.0   0.753389   0.884688    0.644117        0.302319       0.124816   \n",
       "10      1.0   0.792593   0.766294    0.750840        0.240207       0.435518   \n",
       "11      1.0   0.708689   0.758346    0.625886        0.245934       0.288595   \n",
       "12      1.0   0.845121   0.582790    0.843222        0.334799       0.328546   \n",
       "13      1.0   0.213091   0.145044    0.135775        0.338903       0.233536   \n",
       "\n",
       "       History of Magic  Transfiguration   Potions    Charms    Flying  Left  \\\n",
       "Index                                                                          \n",
       "0              0.672324         0.708932  0.431946  0.793213  0.335649   1.0   \n",
       "1              0.617016         0.810917  0.633512  0.248862  0.147696   0.0   \n",
       "2              0.589872         0.966075  0.719760  0.946253  0.460090   1.0   \n",
       "3              0.178215         0.073278  0.258934  0.117970  0.829700   1.0   \n",
       "4              0.245400         0.164015  0.462294  0.130868  0.737070   1.0   \n",
       "5              0.679667         0.778445  0.895932  0.367859  0.318713   0.0   \n",
       "8              0.109860         0.099174  0.274357  0.246298  0.924089   1.0   \n",
       "9              0.659901         0.717590  0.331609  0.462473  0.393842   0.0   \n",
       "10             0.695384         0.690283  0.752667  0.515352  0.534329   0.0   \n",
       "11             0.651182         0.746059  0.582702  0.452979  0.438898   1.0   \n",
       "12             0.724959         0.694238  0.683725  0.478521  0.410453   0.0   \n",
       "13             0.558336         0.936757  0.849164  0.278595  0.219416   1.0   \n",
       "\n",
       "       Right  Gryffindor  Hufflepuff  Ravenclaw  Slytherin  \n",
       "Index                                                       \n",
       "0        0.0         0.0         0.0        1.0        0.0  \n",
       "1        1.0         0.0         0.0        0.0        1.0  \n",
       "2        0.0         0.0         0.0        1.0        0.0  \n",
       "3        0.0         1.0         0.0        0.0        0.0  \n",
       "4        0.0         1.0         0.0        0.0        0.0  \n",
       "5        1.0         0.0         0.0        0.0        1.0  \n",
       "8        0.0         1.0         0.0        0.0        0.0  \n",
       "9        1.0         0.0         1.0        0.0        0.0  \n",
       "10       1.0         0.0         1.0        0.0        0.0  \n",
       "11       0.0         0.0         1.0        0.0        0.0  \n",
       "12       1.0         0.0         1.0        0.0        0.0  \n",
       "13       0.0         0.0         0.0        0.0        1.0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main functionaliity\n",
    "UNNESSESARY_FEATURES = ['Defense Against the Dark Arts', 'Care of Magical Creatures', 'Arithmancy', 'year']\n",
    "\n",
    "\n",
    "# import data\n",
    "df_train = pd.read_csv('dataset_train.csv', index_col='Index')\n",
    "# craete year columns that shouws us cources of students\n",
    "df_train['year'] = df_train['Birthday'].apply(lambda x: int(x.split('-')[0]))\n",
    "df_train['year'] = df_train['year'] - df_train['year'].min()\n",
    "\n",
    "prepared_df = prepare_dataframe(df=df_train, drop_features=UNNESSESARY_FEATURES)\n",
    "prepared_df.head(12)\n",
    "# prepared_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(metaclass=ABCMeta):\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame=None):\n",
    "        self.frame = df\n",
    "        \n",
    "    @property\n",
    "    def frame(self):\n",
    "        if self.__frame is None:\n",
    "            return NotImplemented\n",
    "        return self.__frame\n",
    "    \n",
    "    @frame.setter\n",
    "    def frame(self, df: pd.DataFrame):\n",
    "        if df is not None and not isinstance(df, pd.DataFrame):\n",
    "            raise Exception('Wrong format. Should be pd.DataFrame object')\n",
    "        self.__frame = None\n",
    "        if df is not None:\n",
    "            self.__frame = df.copy()\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        if self.__y is None:\n",
    "            return NotImplemented\n",
    "        return self.__y\n",
    "    \n",
    "    @y.setter\n",
    "    def y(self, y):\n",
    "        self.__y = y\n",
    "        \n",
    "    @property\n",
    "    def X(self):\n",
    "        if self.__X is None:\n",
    "            return NotImplemented\n",
    "        return self.__X\n",
    "    \n",
    "    @X.setter\n",
    "    def X(self, X):\n",
    "        if X is not None and not isinstance(X, pd.DataFrame):\n",
    "            raise Exception('Wrong format. Should be pd.DataFrame object')\n",
    "        self.__X = X\n",
    "        \n",
    "    @property\n",
    "    def theta(self):\n",
    "        if self.__theta is None:\n",
    "            return NotImplemented\n",
    "        return self.__theta\n",
    "        \n",
    "    @theta.setter\n",
    "    def theta(self, theta):\n",
    "        if theta is not None and not isinstance(theta, pd.DataFrame):\n",
    "            raise Exception('Wrong format. Should be pd.DataFrame object')\n",
    "        self.__theta = theta\n",
    "\n",
    "    def set_target_column(self, column_name: str):\n",
    "        \"\"\"\n",
    "        According target column and set X, y, theta values.\n",
    "        \"\"\"\n",
    "        columns = list(self.frame.columns.values)\n",
    "        if column_name not in columns:\n",
    "            raise Exception(f'No <{column_name}> column in dataframe')\n",
    "        indx = columns.index(column_name)\n",
    "        columns.pop(indx)\n",
    "        self.y = pd.DataFrame(self.frame[column_name])\n",
    "        self.X = pd.DataFrame(self.frame[columns])\n",
    "        \n",
    "        theta_names = [f'theta_{i}' for i in range(len(columns))]\n",
    "        theta_shape = (1, len(theta_names))\n",
    "        self.theta = pd.DataFrame(data=np.zeros(theta_shape), columns=theta_names)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     def gradient_step(self, learning_rate: float, loss: np.ndarray, rows: int, X: np.ndarray) -> np.ndarray:\n",
    "#         s = X.T.dot(loss)\n",
    "#         delta_W = 2 * (learning_rate * s / rows)\n",
    "#         return self.W - delta_W\n",
    "    \n",
    "    def cost_gradient(theta, X, y):\n",
    "        predictions = self.sigmoid(X @ theta)\n",
    "        return X.T @ (predictions - y) / len(y)\n",
    "    \n",
    "    # TODO: Investigate why predicted values set to NaN\n",
    "    def cost(self, theta, X, y):\n",
    "        predictions = self.sigmoid(X @ theta)\n",
    "        predictions[predictions == 1] = 0.999\n",
    "        print(predictions[predictions != 0.5])\n",
    "#         print(type(-y.values[0][0]))\n",
    "#         print(np.log(predictions).values[0][0])\n",
    "        error = -y * np.log(predictions) - (1 - y) * np.log(1 - predictions)\n",
    "        return sum(error) / len(y)\n",
    "    \n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def gradient_algorithm(cost: callable, initial_theta, cost_gradient: callable, X, y):\n",
    "        \"\"\"\n",
    "        Minimize a function using a gradient algorithm.\n",
    "        return: Vector of result weights for the model \n",
    "        \"\"\"\n",
    "        # TODO: Gradient algorithm should be implemented\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionBinary(LogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient_algorithm(cost: callable, initial_theta, cost_gradient, X, y):\n",
    "        \"\"\"\n",
    "        Minimize a function using a gradient algorithm.\n",
    "        return: Vector of result weights for the model \n",
    "        \"\"\"\n",
    "        prev_cost = cost(initial_theta, X, y)\n",
    "        prev_theta = initial_theta\n",
    "        while True:\n",
    "            theta = prev_theta - 0.01 * cost_gradient(theta, X, y)\n",
    "            current_cost = cost(theta, X, y)\n",
    "            \n",
    "            print('cost_diff=', abs(current_cost - prev_cost))\n",
    "            if current_cost > prev_cost:\n",
    "                print('current_cost > prev_cost')\n",
    "                break\n",
    "            # add conditions if nessesary\n",
    "            prev_cost = current_cost\n",
    "            prev_theta = theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### test for binary regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "Index    \n",
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "5     NaN\n",
      "8     NaN\n",
      "9     NaN\n",
      "10    NaN\n",
      "11    NaN\n",
      "12    NaN\n",
      "13    NaN\n",
      "14    NaN\n",
      "15    NaN\n",
      "16    NaN\n",
      "17    NaN\n",
      "18    NaN\n",
      "19    NaN\n",
      "20    NaN\n",
      "22    NaN\n",
      "23    NaN\n",
      "24    NaN\n",
      "25    NaN\n",
      "26    NaN\n",
      "27    NaN\n",
      "28    NaN\n",
      "29    NaN\n",
      "30    NaN\n",
      "31    NaN\n",
      "32    NaN\n",
      "...    ..\n",
      "1563  NaN\n",
      "1564  NaN\n",
      "1566  NaN\n",
      "1567  NaN\n",
      "1568  NaN\n",
      "1571  NaN\n",
      "1572  NaN\n",
      "1573  NaN\n",
      "1574  NaN\n",
      "1576  NaN\n",
      "1577  NaN\n",
      "1579  NaN\n",
      "1581  NaN\n",
      "1582  NaN\n",
      "1583  NaN\n",
      "1584  NaN\n",
      "1585  NaN\n",
      "1586  NaN\n",
      "1587  NaN\n",
      "1589  NaN\n",
      "1590  NaN\n",
      "1591  NaN\n",
      "1592  NaN\n",
      "1593  NaN\n",
      "1594  NaN\n",
      "1595  NaN\n",
      "1596  NaN\n",
      "1597  NaN\n",
      "1598  NaN\n",
      "1599  NaN\n",
      "\n",
      "[1333 rows x 1 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-354-ff8b2a743cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(model.X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(model.theta.T.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mLogisticRegressionBinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-353-0185f62bf5eb>\u001b[0m in \u001b[0;36mgradient_algorithm\u001b[0;34m(cost, initial_theta, cost_gradient, X, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprev_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprev_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-352-26e9aaf06ecd>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(self, theta, X, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#         print(np.log(predictions).values[0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "binary_df = FrameHandler.cut_features(prepared_df, ['Hufflepuff', 'Ravenclaw', 'Slytherin'])\n",
    "model = LogisticRegressionBinary(binary_df)\n",
    "model.set_target_column('Gryffindor')\n",
    "model.frame.head(12)\n",
    "model.theta\n",
    "# model.X.dot(model.theta.values.T)\n",
    "# model.X.dot(model.theta.T)\n",
    "# print(model.X.shape)\n",
    "# print(model.theta.T.shape)\n",
    "LogisticRegressionBinary().gradient_algorithm(model.cost, model.theta.values.T, model.cost_gradient, model.X, model.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- 0.0 * -0.023232\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1333, 13) * (1, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-4e34a2e327ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Defense Against the Dark Arts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'house_int'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_ = df_train.dropna(how='any', inplace=False)\n",
    "model = LogisticRegression()\n",
    "model.fit(df_.drop(columns='Defense Against the Dark Arts')._get_numeric_data(), df_['house_int'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(df_.drop(columns='Defense Against the Dark Arts')._get_numeric_data(), df_['house_int'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
